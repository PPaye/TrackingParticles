{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTitle:       Search_By_Triplet + TIME_RESOLUTION + two new cuts. (THE SEARCH OF TRIPLETS WILL BE DIFFERENT\\nStatus:      Stable \\n\\nAutor:       Piter Amador Paye Mamani.\\n\\nDescription:\\n             This python-code is an implementation of the algorithm Search By Triplet that was inspired on the work of\\n             Daniel Campora.           \\nChanges:\\n        * Weak Tracks \\n        * Reviewing the units\\n        * Making changes on the time.\\n        * Finally, the time information is added.\\n        * A very good code without time is completly developed.\\n        * New restrictions are applied at the seeding algorithm.\\n        * \\n        * Implementing the z cut. [doing]\\n        * Change np.arctan() by np.arctan2()\\n\\n1.  Squeletum of the algorithm\\n2.  First Tracks. \\n5.  Adding exceptions. \\n6.  I've deleted unnecessary comments. Also, I was getting an error at time to compute findcandidatewindows.\\n    Problems. One get the values of tracks \\n7.  Changing the jerarquy of the function, according to the paper. It means that findcandidatewindows is calculated\\n    on all modules befero they were processed.\\n6. \\n7. \\n8.  I've added the information of weak_tracks and I've added the information of USED and NOt USED \\n9.  dphi  is a constant value\\n9.  Adding timing information \\n\\n\\n10. In this version I will plot a graphic of efficiency in function of dphi. \\n    Here, I am not concentrating on the plots of the tracks. Only on the plots of the efficiency that depend on dphi.\\n    In other words. I have to run the main program and get the values of the efficiency and then plot. \\n    I am thinking on work only with 0.004 percent of the data. Because it is more fast than all data. \\n    \\n11. Adding TIMING TO THE ALGORITHM.     \\n    To add timing information to the algorithm \\n    I've do it previoues analysis like see if the time difference follow a gaussian distribution.\\n    Plus another important question is to see. How we can add the new restriction to our values. \\n    \\n    I refer that I have to compute the difference in time between t1 and t2 to see if the values surpasses a new technological approach. \\n12. The timing information was added to this algorithm. However, the serach by triplet algorithm is falling according to (probably) \\n    the lost of one variable. It means that when we are using phi, it depend on the x and y. However, the plots that I am getting are good \\n    only for a xy superposed planes. In other words, the window variable on phi is a good candidate but it lost informatin on Z X and Z Y. \\n\\n\""
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from split import *\n",
    "from score import *\n",
    "from scipy import interpolate\n",
    "import time \n",
    "%matplotlib inline \n",
    "import warnings \n",
    "warnings.simplefilter('ignore', np.RankWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\"\"\"\n",
    "Title:       Search_By_Triplet + TIME_RESOLUTION + two new cuts. (THE SEARCH OF TRIPLETS WILL BE DIFFERENT\n",
    "Status:      Stable \n",
    "\n",
    "Autor:       Piter Amador Paye Mamani.\n",
    "\n",
    "Description:\n",
    "             This python-code is an implementation of the algorithm Search By Triplet that was inspired on the work of\n",
    "             Daniel Campora.           \n",
    "Changes:\n",
    "        * Weak Tracks \n",
    "        * Reviewing the units\n",
    "        * Making changes on the time.\n",
    "        * Finally, the time information is added.\n",
    "        * A very good code without time is completly developed.\n",
    "        * New restrictions are applied at the seeding algorithm.\n",
    "        * \n",
    "        * Implementing the z cut. [doing]\n",
    "        * Change np.arctan() by np.arctan2()\n",
    "\n",
    "1.  Squeletum of the algorithm\n",
    "2.  First Tracks. \n",
    "5.  Adding exceptions. \n",
    "6.  I've deleted unnecessary comments. Also, I was getting an error at time to compute findcandidatewindows.\n",
    "    Problems. One get the values of tracks \n",
    "7.  Changing the jerarquy of the function, according to the paper. It means that findcandidatewindows is calculated\n",
    "    on all modules befero they were processed.\n",
    "6. \n",
    "7. \n",
    "8.  I've added the information of weak_tracks and I've added the information of USED and NOt USED \n",
    "9.  dphi  is a constant value\n",
    "9.  Adding timing information \n",
    "\n",
    "\n",
    "10. In this version I will plot a graphic of efficiency in function of dphi. \n",
    "    Here, I am not concentrating on the plots of the tracks. Only on the plots of the efficiency that depend on dphi.\n",
    "    In other words. I have to run the main program and get the values of the efficiency and then plot. \n",
    "    I am thinking on work only with 0.004 percent of the data. Because it is more fast than all data. \n",
    "    \n",
    "11. Adding TIMING TO THE ALGORITHM.     \n",
    "    To add timing information to the algorithm \n",
    "    I've do it previoues analysis like see if the time difference follow a gaussian distribution.\n",
    "    Plus another important question is to see. How we can add the new restriction to our values. \n",
    "    \n",
    "    I refer that I have to compute the difference in time between t1 and t2 to see if the values surpasses a new technological approach. \n",
    "12. The timing information was added to this algorithm. However, the serach by triplet algorithm is falling according to (probably) \n",
    "    the lost of one variable. It means that when we are using phi, it depend on the x and y. However, the plots that I am getting are good \n",
    "    only for a xy superposed planes. In other words, the window variable on phi is a good candidate but it lost informatin on Z X and Z Y. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho(x,y):\n",
    "    return np.sqrt(x*x + y*y)\n",
    "def r(x,y,z):\n",
    "    return np.sqrt(x*x + y*y + z*z)\n",
    "def theta(x,y,z):\n",
    "    return np.arccos(z/r(x,y,z))\n",
    "def phi(x,y):\n",
    "    return np.arctan2(y/x)\n",
    "def module(r):\n",
    "    return np.sqrt(np.sum(r*r))\n",
    "def r_e(z, r_l, r_c):\n",
    "    z_c = r_c[2] \n",
    "    r_versor = (r_l - r_c)/module(r_l - r_c)               # computing r_versor\n",
    "    r_versor_dot_z_versor = r_versor[2]  \n",
    "    return r_c - r_versor/r_versor_dot_z_versor*(z_c - z)  # IMPORTANT WITH THE MINUS SIGN.\n",
    "def correct_time(hit_time, x, y, z):\n",
    "    c = 0.299792 #[cm/ps] Light Velocity in [mm/ps]        # sigma_z_origin \n",
    "    travel_time = np.sqrt(x*x + y*y + z*z)/c\n",
    "    return hit_time - travel_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtheta(x, dx, y, dy):\n",
    "    # definition of theta = arctan(x,y)\n",
    "    return np.arctan2(- x*dy + dx*y) / y**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_theta():\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_time():\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_z():\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_x():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_y():\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_data(fraction, event):\n",
    "    global time_resolution           # Adding a time resolution to our analysis of tracks\n",
    "    \"\"\"\n",
    "    EVENT\n",
    "    55microns50psInner55microns50psOuter_EventNumber.txt\n",
    "    \n",
    "    25microns0psInner200microns50psOuter_test.txt\n",
    "    25microns0psInner200microns50psOuter_train.txt\n",
    "    25microns75psInner25microns75psOuter_test.txt\n",
    "    25microns75psInner25microns75psOuter_train.txt\n",
    "    55microns0psInner55microns0psOuter_test.txt\n",
    "    55microns0psInner55microns0psOuter_train.txt\n",
    "    55microns100psInner200microns50psOuter_test.txt\n",
    "    55microns100psInner200microns50psOuter_train.txt\n",
    "    55microns50psInner55microns50psOuter_test.txt\n",
    "    55microns50psInner55microns50psOuter_train.txt\n",
    "    \n",
    "    RAMPData25microns0psInner200microns50psOuter_test.txt\n",
    "    RAMPData25microns0psInner200microns50psOuter_train.txt\n",
    "    RAMPData25microns75psInner25microns75psOuter_test.txt\n",
    "    RAMPData25microns75psInner25microns75psOuter_train.txt\n",
    "    RAMPData55microns0psInner55microns0psOuter_test.txt\n",
    "    RAMPData55microns0psInner55microns0psOuter_train.txt\n",
    "    RAMPData55microns100psInner200microns50psOuter_test.txt\n",
    "    RAMPData55microns100psInner200microns50psOuter_train.txt\n",
    "    RAMPData55microns50psInner200microns50psOuter_test.txt\n",
    "    RAMPData55microns50psInner200microns50psOuter_train.txt\n",
    "    RAMPData55microns50psInner55microns50psOuter_test.txt\n",
    "    RAMPData55microns50psInner55microns50psOuter_train.txt\n",
    "    RAMPsmeared55microns200psInner55microns50psOuter_test.txt\n",
    "    RAMPsmeared55microns200psInner55microns50psOuter_train.txt\n",
    "    test.txt\n",
    "    testTrain.txt\n",
    "    \"\"\"\n",
    "    name = 'data2/55microns50psInner55microns50psOuter_EventNumber.txt' # To be modified for others files. \n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df = pd.read_csv(name, sep=' ')              # All data.\n",
    "    \n",
    "    columns = df.columns.values\n",
    "    columns[9] = 'Event'\n",
    "    df.columns = columns\n",
    "\n",
    "    df_tmp = df.query(f'Event == {event}' ) #.copy(deep = True)  # inplace=True)\n",
    "    \n",
    "    df_tmp2, _ = split_frac(df_tmp, fraction)\n",
    "    \n",
    "    return df_tmp2        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortbyphi():\n",
    "    '''Description:\n",
    "    Sort each D_i increasingly accoording to phi\n",
    "    And add a column to the dataframe_module with the name of used to accept or neglect hits. \n",
    "    '''\n",
    "    global time_resolution  \n",
    "    global df \n",
    "    global sigma_z \n",
    "\n",
    "    df['phi']   = np.arctan2(df['x'], df['y'])                        \n",
    "    df['t_c']   = correct_time(df['t'], df['x'], df['y'], df['z'])        \n",
    "    #df['used'] = False                                             \n",
    "    df['used']  = 0  \n",
    "    \n",
    "    modules = []\n",
    "    z_modules = [-277.0, -252.0, -227.0, -202.0, -132.0, -62.0, -37.0, -12.0, 13.0, 38.0, 63.0, 88.0, 113.0, 138.0, 163.0, 188.0, 213.0, 238.0, 263.0, 325.0, 402.0, 497.0, 616.0, 661.0, 706.0, 751.0]\n",
    "    \n",
    "    for z_m in z_modules:  \n",
    "        #print(sigma_z)\n",
    "        mod = df.query(f\" {z_m} - {sigma_z} <= z <= {z_m} + {sigma_z}\").copy(deep=True)\n",
    "        mod['z_mod'] = z_m\n",
    "        #mod.loc[mod.index.values, \"z_mod\"] = z_m\n",
    "        #mod.loc[mod.index.values, \"used\"]  = False\n",
    "        # IMPORTANT \n",
    "        mod = mod.sort_values('phi', ascending=True)\n",
    "        #print(\"Index \", mod['t_c'])\n",
    "        modules.append(mod)  \n",
    "    tmp_df =pd.DataFrame()\n",
    "    for mod in modules:\n",
    "        tmp_df = pd.concat([tmp_df, mod])\n",
    "    df = tmp_df\n",
    "    #print(df['t_c'])\n",
    "    return modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PHI = []\n",
    "def findcandidatewindows(left_mod, mod, right_mod ):\n",
    "    #global left_mod, mod, right_mod\n",
    "    #(left_mod, mod, right_mod ):\n",
    "    global time_resolution               # Adding a time resolution to our analysis of tracks\n",
    "    # phi_window     =  phi_extrapolation_base + np.abs( hit_Zs[h_center]) * phi_extrapolation_coef \n",
    "    global phi_extrapolation_coef, phi_extrapolation_base , dphi\n",
    "    '''Description: \n",
    "        Compute the first and last candidates(the window) according to acceptance range(dphi) for each hit.\n",
    "        SUPPOSSING THAT ALL DATA ARE ORDERED ACCOURDING TO PHI. THIS PROCCESS WAS DONE Previously\n",
    "        In case of add more information to the modules, one easily can add throught the iteration \n",
    "    '''\n",
    "    # CONVENTION :     \n",
    "    # l_m  m  r_m   the values are ordered.      \n",
    "    #  |   |   |             \n",
    "    #  |   |   |    phi up  \n",
    "    #  |   |   |    phi      \n",
    "    #  |   |   |    phi down \n",
    "    #  |   |   |          \n",
    "    \n",
    "    right_hit_max = [] \n",
    "    right_hit_min = [] \n",
    "\n",
    "    temporal = mod['phi'] \n",
    "    \n",
    "    # ITERATION OVER PHI FOR RIGHT \n",
    "    \n",
    "    for phi_i in mod['phi']: \n",
    "        #print(\"=\")\n",
    "        #print(phi_i)\n",
    "        if str(phi_i) == 'nan' :     \n",
    "            #print(phi_i, \"the value of phi_i is NaN ON RIGHT\")\n",
    "            m = \"nan\"               # minumum hit \n",
    "            M = \"nan\"               # maximum hit\n",
    "            right_hit_min.append(m) \n",
    "            right_hit_max.append(M) \n",
    "            continue # \n",
    "        if str(phi_i) == 'NaN' :     \n",
    "            #print(phi_i, \"the value of phi_i is NaN ON RIGHT\")\n",
    "            m = \"nan\"               # minumum hit \n",
    "            M = \"nan\"               # maximum hit\n",
    "            left_hit_min.append(m) \n",
    "            left_hit_max.append(M) \n",
    "            continue # \n",
    "            \n",
    "        z_center = mod['z_mod'].unique()[0]\n",
    "        #z = df.query(f\"phi=={phi_i}\")[\"z\"].values[0]\n",
    "        # GET HIT \n",
    "        \"\"\" dphi =  phi_extrapolation_base + np.abs( z_center ) * phi_extrapolation_coef \"\"\"\n",
    "\n",
    "        #PHI.append(dphi)\n",
    "        down      = phi_i - dphi \n",
    "        up        = phi_i + dphi \n",
    "        #print(down, up)\n",
    "        \n",
    "        condition = f'{down} <= phi <=  {up}'\n",
    "        tmp_df = right_mod.query(condition)\n",
    "        if not tmp_df.empty:\n",
    "            m = tmp_df['hit_id'][tmp_df.index[0]]     # minumum hit \n",
    "            M = tmp_df['hit_id'][tmp_df.index[-1]]    # maximum hit \n",
    "            right_hit_min.append(m) \n",
    "            right_hit_max.append(M) \n",
    "        elif tmp_df.empty :\n",
    "\n",
    "            m = \"nan\" #pd.np.nan                      # minumum hit \n",
    "            M = \"nan\" #pd.np.nan                      # maximum hit\n",
    "            right_hit_min.append(m)  \n",
    "            right_hit_max.append(M) \n",
    "            \n",
    "    left_hit_max = [] \n",
    "    left_hit_min = [] \n",
    "    # ITERATION OVER PHI FOR LEFT\n",
    "    for phi_i in mod['phi']:\n",
    "        if str(phi_i) == 'NaN' :     \n",
    "            # print(phi_i, \"the value of phi_i is NaN ON LEFT\")\n",
    "            m = \"nan\"               # minumum hit \n",
    "            M = \"nan\"               # maximum hit\n",
    "            left_hit_min.append(m) \n",
    "            left_hit_max.append(M) \n",
    "            continue # \n",
    "        if str(phi_i) == 'nan' :     \n",
    "            # print(phi_i, \"the value of phi_i is NaN ON left\")\n",
    "            m = \"nan\"               # minumum hit \n",
    "            M = \"nan\"               # maximum hit\n",
    "            left_hit_min.append(m) \n",
    "            left_hit_max.append(M) \n",
    "            continue # \n",
    "        # GET HIT \n",
    "        down      = phi_i - dphi \n",
    "        up        = phi_i + dphi \n",
    "        condition = f'{down} <= phi <= {up}'\n",
    "        tmp_df = left_mod.query(condition)\n",
    "        #print(\"len LEFT\", len(tmp_df))\n",
    "        if not tmp_df.empty :\n",
    "            m = tmp_df['hit_id'][tmp_df.index[0]]        # minumum hit \n",
    "            M = tmp_df['hit_id'][tmp_df.index[-1]]       # maximum hit  \n",
    "            left_hit_min.append(m)\n",
    "            left_hit_max.append(M)\n",
    "        elif tmp_df.empty :\n",
    "            # print(\"data_frame is empty LEFT\")\n",
    "            m = \"nan\"               # minumum hit \n",
    "            M = \"nan\"               # maximum hit\n",
    "            left_hit_min.append(m) \n",
    "            left_hit_max.append(M) \n",
    "            \n",
    "    mod[\"right_hit_max\"] = right_hit_max  \n",
    "    mod[\"right_hit_min\"] = right_hit_min  \n",
    "    mod[\"left_hit_max\"]  = left_hit_max   \n",
    "    mod[\"left_hit_min\"]  = left_hit_min                                                                                    \n",
    "    return mod\n",
    "\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrapolation_on_center_module(r_right, r_left, z_center):\n",
    "    # IMPORTANT\n",
    "    # the values then have the next form:\n",
    "    # np(r_right), np(r_left), float(r_left)\n",
    "    #modules |  |  |\n",
    "    #        l  c  r\n",
    "    r_versor = (r_right - r_left)/module(r_right - r_left)   #  \n",
    "    distance = abs( z_center - r_left[2] )                   # \n",
    "    r_center = r_left + distance / ( np.dot(r_versor, np.array([0,0,1]) ) ) * r_versor\n",
    "    return r_center "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrapolation_to_origin(r1, r2, y):   # only works for y\n",
    "                                          # in case to extrapolate for x you only need to change the values of r2 ->y2 and the unitary versor\n",
    "    r_versor = (r1 - r2)/module(r1 - r2)  \n",
    "    y2       = r2[1] \n",
    "    r_origin = r2 + (y2 - y)/( np.dot(r_versor, np.array([0,-1,0]) ) ) * r_versor \n",
    "    return r_origin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_L = []\n",
    "T_R = []\n",
    "T_C = []\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "Z = []\n",
    "\n",
    "def trackseeding():\n",
    "    global flagged\n",
    "    global sigma_z_origin\n",
    "    global dx, dy\n",
    "    global M_i\n",
    "    global time_resolution                             # Adding a time resolution to our analysis of tracks\n",
    "\n",
    "    global left_mod, mod, right_mod, M_i, dphi, sigma_t\n",
    "    '''\n",
    "    Description: \n",
    "        Checks the preceding and following modules for compatible hits using the above results.\n",
    "        \n",
    "        All triplets in the search window are fitted and compared.\n",
    "        \n",
    "        and the best one is kept as a track seed.\n",
    "        \n",
    "        stores its best found triplet\n",
    "        Finding triplets is ap- plied in first instance to the modules\n",
    "        that are further apart from the collision point\n",
    "        Each triplet is the seed of a forming track\n",
    "    '''\n",
    "    #Necessary functions.\n",
    "    def fit(triplet): \n",
    "        phi_data = [ df.query(f'hit_id == {hit}')['phi']     for hit in triplet ]\n",
    "        z_data   = [ df.query(f'hit_id == {hit}')['z_mod']   for hit in triplet ]\n",
    "        phi_data = [ hit.values[0] for hit in phi_data                      ]                        \n",
    "        z_data   = [ hit.values[0] for hit in z_data                        ]                    \n",
    "        # Kind of fit: Linear\n",
    "        fitting = np.polyfit(phi_data, z_data, 1)\n",
    "        chiSquared = np.sum((np.polyval(fitting, z_data) - phi_data)**2)\n",
    "        return chiSquared\n",
    "\n",
    "    df_triplets = []\n",
    "    #print(\"error ??????\", mod )\n",
    "    # print(\"error_mod.columns:\", mod.columns)\n",
    "    for index, part in mod.iterrows():\n",
    "\n",
    "        r_hit_max, r_hit_min = part[\"right_hit_max\"], part[\"right_hit_min\"]  \n",
    "        l_hit_max, l_hit_min = part[\"left_hit_max\"],  part[\"left_hit_min\" ] \n",
    "        \n",
    "        if  str(r_hit_max)  == \"nan\":\n",
    "            continue \n",
    "        elif str(r_hit_min) == \"nan\":\n",
    "            continue \n",
    "        elif str(l_hit_max) == \"nan\":\n",
    "            continue \n",
    "        elif str(l_hit_min) == \"nan\":\n",
    "            continue  \n",
    "        if  str(r_hit_max)  == \"NaN\" :\n",
    "            continue \n",
    "        elif str(r_hit_min) == \"NaN\" :\n",
    "            continue \n",
    "        elif str(l_hit_max) == \"NaN\" :\n",
    "            continue \n",
    "        elif str(l_hit_min) == \"NaN\" :\n",
    "            continue  \n",
    "        r_phi_max = right_mod.query(f\"hit_id == {r_hit_max}\")['phi'].values[0]   \n",
    "        r_phi_min = right_mod.query(f\"hit_id == {r_hit_min}\")['phi'].values[0]   \n",
    "                                                                                 \n",
    "        l_phi_max = left_mod.query(f\"hit_id == {l_hit_max}\")['phi'].values[0]   \n",
    "        l_phi_min = left_mod.query(f\"hit_id == {l_hit_min}\")['phi'].values[0]     \n",
    "        \n",
    "        tmp_right = right_mod.query(f\"   {r_phi_min} <= phi <= {r_phi_max} & used <= {flagged} \")    # ADDING TIME\n",
    "        for hit_right in tmp_right['hit_id'].values:\n",
    "            tmp_left = left_mod.query(f\" {l_phi_min} <= phi <= {l_phi_max} & used <= {flagged} \")     # ADDING TIME\n",
    "            for hit_left in tmp_left['hit_id'].values:         \n",
    "                \n",
    "                #hit_left   = int( tmp_left.query( f\" phi == {L}\")['hit_id'].values[0]  )  \n",
    "                hit_center = int( part[\"hit_id\"] )\n",
    "                #hit_right  = int( tmp_right.query(f\" phi == {R}\")['hit_id'].values[0]  )\n",
    "                \n",
    "                try :\n",
    "                    r_right  = tmp_right.query(f'hit_id == {hit_right} ')[['x', 'y','z']].to_numpy()[0]\n",
    "                    z_center = part['z_mod']                            \n",
    "                    r_left   = tmp_left.query(f'hit_id == {hit_left} ')[['x', 'y','z']].to_numpy()[0]\n",
    "                except :\n",
    "                    print(\"here there is a problem\")\n",
    "                    return 1\n",
    "                \n",
    "                try :\n",
    "                    r_center_extrapolation = extrapolation_on_center_module(r_right, r_left, z_center)\n",
    "                    # MAKING A PROOF ON THE EXTRAPOLATION OF DATA. PLOTING THE VALUES OF X Y Z \n",
    "                    # make a plot of r_left and r_right and r_extrapolated\n",
    "                    #r_left, r_center_extrapolation, r_right \n",
    "                    \n",
    "                    x_hits = [r_left[0], r_center_extrapolation[0], r_right[0] ]\n",
    "                    y_hits = [r_left[1], r_center_extrapolation[1], r_right[1] ]\n",
    "                    z_hits = [r_left[2], r_center_extrapolation[2], r_right[2] ]\n",
    "                    \n",
    "                    verification = r_left[2] < r_center_extrapolation[2] < r_right[2]\n",
    "                    if verification == False :\n",
    "                        print(\"verifing if the value of z_center is on the \")\n",
    "                        print(verification)\n",
    "                    #print(temporal, type(temporal))\n",
    "                except :    \n",
    "                    print(\"here is the error ==\")\n",
    "                    return 1 \n",
    "                ############################################################################################################ \n",
    "                ############################################################################################################ \n",
    "                ########################################   CUT on Z   ###################################################### \n",
    "                ############################################################################################################   \n",
    "                ############################################################################################################ \n",
    "                try:\n",
    "                    x0 , y0,  z0 = extrapolation_to_origin(r_right, r_left, 0) \n",
    "                    #if y0 != 0 :\n",
    "                    #    print(\"the value of y0 is :\", y0)\n",
    "                    #X.append(x0) \n",
    "                    #Y.append(y0) \n",
    "                    #Z.append(z0) \n",
    "                    if  abs(z0) > sigma_z_origin:\n",
    "                        #print(\"z0 > sigma_origin: \")\n",
    "                        continue \n",
    "                except : \n",
    "                    print(\"cut on z is the error\")\n",
    "\n",
    "                ############################################################################################################ \n",
    "                ############################################################################################################ \n",
    "                ########################################   NEW WINDOW on X and Y   ######################################### \n",
    "                ############################################################################################################ \n",
    "                ############################################################################################################\n",
    "                left_cut_x  = r_center_extrapolation[0] - dx \n",
    "                right_cut_x = r_center_extrapolation[0] + dx  \n",
    "                \n",
    "                down_cut_y  = r_center_extrapolation[1] - dy \n",
    "                up_cut_y    = r_center_extrapolation[1] + dy       \n",
    "                \n",
    "                # print(\"left_cut_x\", \"right_cut_x\", \"down_cut_y\", \"up_cut_y\")\n",
    "                # print(left_cut_x, right_cut_x, down_cut_y, up_cut_y)\n",
    "                \n",
    "                try : \n",
    "                    ############################################################################################################ \n",
    "                    ############################################################################################################ \n",
    "                    ########################################   DEEP CONDITION on X and Y   ##################################### \n",
    "                    ############################################################################################################ \n",
    "                    ############################################################################################################\n",
    "                    x = part['x']\n",
    "                    y = part['y']\n",
    "                    #print(\"verifying the kind of x and y \", x, y, type(x), type(y))\n",
    "                    \n",
    "                    new_window = mod.query(f\" {left_cut_x}  < x < {right_cut_x} & {down_cut_y} < y < {up_cut_y} \").copy(deep=True) \n",
    "                    if  (left_cut_x  < x < right_cut_x) and (down_cut_y < y < up_cut_y) :\n",
    "                        \"\"\"\n",
    "                        #if len(new_window) > 0 :\n",
    "                        print(\"PROOF\", part[['x', 'y', 'z']].to_numpy())\n",
    "                        point = part[['x', 'y', 'z']].to_numpy()\n",
    "                        plt.plot(z_hits, x_hits) \n",
    "                        plt.scatter(z_hits + [ point[2], point[2], point[2]], x_hits+[point[0], left_cut_x, right_cut_x] )\n",
    "                        plt.xlabel(\"z\")\n",
    "                        plt.ylabel(\"x\")\n",
    "                        plt.show() \n",
    "                        plt.plot(z_hits, y_hits ) \n",
    "                        plt.scatter(z_hits + [ point[2], point[2], point[2]], y_hits+[point[1], down_cut_y, up_cut_y] )\n",
    "                        plt.xlabel(\"z\")\n",
    "                        plt.ylabel(\"y\")\n",
    "                        plt.show()\n",
    "                        \"\"\"\n",
    "                        pass\n",
    "\n",
    "                    else:\n",
    "                        continue \n",
    "                except : \n",
    "                    print(\"the new window has a syntax error\")\n",
    "                    return\n",
    "                \n",
    "                #print(\"print the new window\", len(new_window)\n",
    "                \n",
    "                ############################################################################################################ \n",
    "                ############################################################################################################ \n",
    "                ########################################   TIMING   ######################################################## \n",
    "                ############################################################################################################ \n",
    "                ############################################################################################################ \n",
    "\n",
    "                # NOTATION: 't_c' is the corrected time. Against of t_c that is the time variable of the modules t_center        \n",
    "                \n",
    "                if time_resolution == True :\n",
    "                    # print(\"time_resolution == True\")\n",
    "                    t_l =   left_mod.query(f'hit_id == {hit_left}')['t_c'].values[0]\n",
    "                    t_c =      mod.query(f'hit_id == {hit_center}')['t_c'].values[0]\n",
    "                    t_r = right_mod.query(f'hit_id == {hit_right}')['t_c'].values[0]\n",
    "\n",
    "                    # CONDITIONS:\n",
    "                    T_L.append(abs(t_l - t_c))\n",
    "                    T_C.append(abs(t_c - t_r))\n",
    "                    T_R.append(abs(t_l - t_r))\n",
    "                    \n",
    "                    if abs(t_l - t_c) > 3*sigma_t :\n",
    "                        continue\n",
    "                    if abs(t_c - t_r) > 3*sigma_t :\n",
    "                        continue\n",
    "                    if abs(t_l - t_r) > 3*sigma_t :\n",
    "                        continue\n",
    "                ############################################################################################################\n",
    "                ############################################################################################################\n",
    "                ############################################################################################################\n",
    "                ############################################################################################################\n",
    "                ############################################################################################################\n",
    "                \n",
    "                # With this data we have built the triplets. \n",
    "                triplets = [hit_left, hit_center, hit_right] \n",
    "                \n",
    "                # This a lost of memory. I mean that call by hits and not by values is a lost of memory.\n",
    "                chi2 = fit(triplets)                                                                                                                                                                \n",
    "                # Finally we append the values of the data to a df_triplets\n",
    "                df_triplets.append(list(triplets)+[chi2])\n",
    "                        \n",
    "    df_triplets = pd.DataFrame(df_triplets, columns = ['left_hit', 'hit', 'right_hit', 'chi2'])  \n",
    "    # Up to this point it is necessary to have the values of df_triplets complete\n",
    "    # Then the algorithm should continue to get the best choices according to the values\n",
    "    # of chi2. \n",
    "    \n",
    "    def best_choice(df_triplets):\n",
    "        seeds = []\n",
    "        for hit_c in df_triplets['hit'].unique() : # UNIQUE\n",
    "            # GROUPING \n",
    "            tmp = df_triplets.query(f'hit == {hit_c}')\n",
    "            minimum = (tmp['chi2']).idxmin()\n",
    "            t = (tmp.loc[minimum]).values     \n",
    "            t = [int(i) for i in t[:3]]\n",
    "            #these are the triplets       \n",
    "            \n",
    "            seeds.append(list(t[:3]))     # Here I am negleting the information chi2 because is not important\n",
    "        return seeds                      # obviously it is a track\n",
    "    \n",
    "    seeds = best_choice(df_triplets)\n",
    "    \n",
    "    for seed in seeds:\n",
    "            # #########     MARKING TRIPLES######  \n",
    "            # MATCHING EACH HIT AS USED ON THE WORKING MODULE  \n",
    "            hit_id_left, hit_id_center, hit_id_right = seed \n",
    "            #LEFT\n",
    "            #left_mod.loc[   left_mod.hit_id == hit_id_left,    \"used\" ]     = True\n",
    "            left_mod.loc[   left_mod.hit_id == hit_id_left,    \"used\" ]     += 1\n",
    "            #CENTER\n",
    "            #mod.loc[           mod.hit_id   == hit_id_center,  \"used\" ]     = True\n",
    "            mod.loc[           mod.hit_id   == hit_id_center,  \"used\" ]     += 1\n",
    "            #RIGTH\n",
    "            #right_mod.loc[ right_mod.hit_id == hit_id_right,   \"used\" ]     = True\n",
    "            right_mod.loc[ right_mod.hit_id == hit_id_right,   \"used\" ]     += 1\n",
    "  \n",
    "    return seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_forwarding():\n",
    "    global dx, dy\n",
    "    global frozen_tracks                 \n",
    "    global time_resolution              \n",
    "    global tracks, work_module, left_mod, mod, right_mod, M_i, weak_tracks \n",
    "    global phi_extrapolation_coef, phi_extrapolation_base \n",
    "    \n",
    "    new_tracks = []      \n",
    "    #frozen_tracks = []   \n",
    "    # Notation:\n",
    "    # x0, y0, z0 is the EXTRAPOLATED track.               \n",
    "    # X,  Y,  Z  is the last track on previous module.   \n",
    "    # x,  y,  z  is the tracks on a window.                                                                 \n",
    "    # Searching tracks on phi_e - dphi < phi < phi_e + dphi that minimize the extrapolated function.\n",
    "    # r0 = np.array([x0, y0, z0] )\n",
    "    # r  = np.array([x, y, 1]    )\n",
    "    # R  = np.array([X,  Y,  Z ] )\n",
    "    \n",
    "    def module(r):\n",
    "        return np.sqrt(np.sum(r*r))\n",
    "    def ext_func(r0, r1, r):\n",
    "        # r0, r1, r are arrays\n",
    "        dx2_plus_dy2 = module(  r0-r )     # distance between hits on the working module.  \n",
    "        \"\"\"dz2       = module( r1-r0 )     # distance between the last two modules.                                \n",
    "        return dx2_plus_dy2/dz2 \n",
    "        \"\"\"  \n",
    "        return dx2_plus_dy2 \n",
    "    \n",
    "    try: \n",
    "        z_e = work_module['z_mod'].unique()[0]  # z_position of work_module  # an array  \n",
    "    except :\n",
    "        \n",
    "        print(\"possible error on work_module. Probably it not have values\" )\n",
    "        return \"error\"\n",
    "    \n",
    "    #######################################################\n",
    "    #######################################################\n",
    "    ###########   PRINCIPAL LOOP OVER tracks ##############\n",
    "    #######################################################\n",
    "    #######################################################\n",
    "    for track in tracks:          \n",
    "        # print(\"error\", time_resolution)\n",
    "        #PROOF: Do you have the track values information of USED ?\n",
    "        data = []   \n",
    "        vector_data = []\n",
    "        #EXTRAPOLATION ONLY WITH TWO LAST HITS \n",
    "        for hit in track[0:2] :\n",
    "            data.append(tuple((df.query(f'hit_id == {hit}')[['phi', 'z_mod']]).values[0]))     \n",
    "            vector_data.append(tuple((df.query(f'hit_id == {hit}')[['x', 'y', 'z_mod']]).values[0]))\n",
    "        phi_data, z_data = zip(*data) \n",
    "        \n",
    "        #EXTRAPOLATED SEGMENT FUNCTION      \n",
    "        ext_seg = interpolate.interp1d(z_data, phi_data, fill_value = \"extrapolate\" )\n",
    "        phi_e   = ext_seg( z_e )                   # an array \n",
    "        r_l, r_c = vector_data                     # THE VALUES ON LEFT AND RIGHT                                                \n",
    "        r_l, r_c = np.array(r_l), np.array(r_c)    # \n",
    "        x_e, y_e, z_e = r_e(z_e, r_l, r_c)         # COMPUTING THE VALUES ON THE WORKING MODULE.  \n",
    "        \n",
    "        \n",
    "        ## REFINING  df_work_module_window #######################################################################################\n",
    "        ####################################### dX and dY WINDOW #################################################################\n",
    "        ##########################################################################################################################\n",
    "        ############################### REMEMBER: work_module, left_mod, mod            ##########################################\n",
    "        ##########################################################################################################################\n",
    "        \n",
    "        #Open a Window centered on phi_e: \n",
    "        z_center = mod['z_mod'].unique()[0]\n",
    "        #z = df.query(f\"phi=={phi_i}\")[\"z\"].values[0]\n",
    "        # GET HIT \n",
    "        \"\"\" dphi =  phi_extrapolation_base + np.abs( z_center ) * phi_extrapolation_coef \"\"\"\n",
    "        down = phi_e - dphi\n",
    "        up   = phi_e + dphi   \n",
    "        #####################are down or up  NaN values?####################################\n",
    "        if str(down) == 'nan' or str(down) == 'NaN' or str(up) == 'nan' or str(up) == 'NaN':\n",
    "            print(\"An error ocurred with the values of down or up. Plese cheack.\")\n",
    "            break\n",
    "        \n",
    "        #######################################################################\n",
    "        ######################          TIMING        #########SWITCH########## \n",
    "        #######################################################################\n",
    "        if time_resolution == True : \n",
    "            h_l = track[0]   \n",
    "            h_c = track[1]   \n",
    "            h_r = track[2]  \n",
    "            t1 = df.query( f\"hit_id == {h_l}  \"   )['t_c'].values[0]   #  track      \n",
    "            t2 = df.query( f\"hit_id == {h_c}  \"   )['t_c'].values[0]   #  track       \n",
    "            t3 = df.query( f\"hit_id == {h_r}  \"   )['t_c'].values[0]   #  track\n",
    "\n",
    "        if   time_resolution == True  :        # on all cases where be necessary\n",
    "            df_work_module_window = work_module.query(f\"{down} <= phi <= {up}  & abs(t_c - 1/3.*( {t1} + {t2} + {t3} ) ) <= 3*{sigma_t}\")\n",
    "        elif time_resolution == False :\n",
    "            df_work_module_window = work_module.query(f\"{down} <= phi <= {up}\") \n",
    "        \n",
    "\n",
    "        ############################################################################################################\n",
    "        ####################################### EXTRAPOLATION TO THE ORIGIN ########################################\n",
    "        ############################################################################################################ \n",
    "        ########################################   CUT on Z   ###################################################### \n",
    "        ############################################################################################################\n",
    "        hit_1, hit_2, hit_3 = track[0:3]\n",
    "        # work_module, left_mod, mod \n",
    "        try :\n",
    "            r_right  = df.query(f'hit_id == {hit_1} ')[['x', 'y','z']].to_numpy()[0]\n",
    "            z_center = df.query(f'hit_id == {hit_2} ')[['x', 'y','z']].to_numpy()[0]                            \n",
    "            r_left   = df.query(f'hit_id == {hit_3} ')[['x', 'y','z']].to_numpy()[0]\n",
    "        except :\n",
    "            print(\"here there is a problem\")\n",
    "            return \"error\"\n",
    "        try:\n",
    "            x0 , y0,  z0 = extrapolation_to_origin(r_right, r_left, 0) \n",
    "            if  abs(z0) > sigma_z_origin:\n",
    "                continue \n",
    "        except : \n",
    "            print(\"cut on z is the error\")\n",
    "        \n",
    "        hit_left = track[0]   \n",
    "        R  = df.query(f'hit_id == {hit_left}')[['x','y','z_mod']].values[0]  \n",
    "        r0 = np.array([x_e, y_e ,z_e ])\n",
    "        \n",
    "        #\"************************************************************************************************************\"\n",
    "        #\"***************************Searching CANDIDADATES on the working module*************************************\"\n",
    "        #\"************************************************************************************************************\"\n",
    "        \n",
    "        tmp_candidates = []\n",
    "        for index, row in df_work_module_window.iterrows(): \n",
    "            # Here I only need to have the information of position.    \n",
    "            r      =  row[['x', 'y', 'z_mod']].values \n",
    "            #\"************************************************************************************************************\"\n",
    "            #\"***************************Searching CANDIDADATES on the working module*************************************\"\n",
    "            #\"************************************************************************************************************\"    \n",
    "            ## REFINING  df_work_module_window ############################################################################\n",
    "            ####################################### dX and dY WINDOW ######################################################\n",
    "            ###############################################################################################################\n",
    "            ############################### REMEMBER: work_module, left_mod, mod            ###############################\n",
    "            ###############################################################################################################\n",
    "            \n",
    "            ############################################################################################################### \n",
    "            ########################################   NEW WINDOW on X and Y   ############################################ \n",
    "            ############################################################################################################### \n",
    "            left_cut_x  = x_e - dx \n",
    "            right_cut_x = x_e + dx  \n",
    "            down_cut_y  = y_e - dy \n",
    "            up_cut_y    = y_e + dy \n",
    "            try : \n",
    "                ############################################################################################################ \n",
    "                ########################################   DEEP CONDITION on X and Y   ##################################### \n",
    "                ############################################################################################################ \n",
    "                #print(\"verifying the kind of x and y \", x, y, type(x), type(y))\n",
    "                df_work_module_window = df_work_module_window.query(f\" {left_cut_x}  < x < {right_cut_x} & {down_cut_y} < y < {up_cut_y} \").copy(deep=True)\n",
    "                x = r[0] \n",
    "                y = r[1] \n",
    "                if  (left_cut_x < x < right_cut_x) and (down_cut_y < y < up_cut_y) :\n",
    "                    \"\"\"\n",
    "                    #if len(new_window) > 0 :\n",
    "                    print(\"PROOF\", part[['x', 'y', 'z']].to_numpy())\n",
    "                    point = part[['x', 'y', 'z']].to_numpy()\n",
    "                    plt.plot(z_hits, x_hits) \n",
    "                    plt.scatter(z_hits + [ point[2], point[2], point[2]], x_hits+[point[0], left_cut_x, right_cut_x] )\n",
    "                    plt.xlabel(\"z\")\n",
    "                    plt.ylabel(\"x\")\n",
    "                    plt.show() \n",
    "                    plt.plot(z_hits, y_hits ) \n",
    "                    plt.scatter(z_hits + [ point[2], point[2], point[2]], y_hits+[point[1], down_cut_y, up_cut_y] )\n",
    "                    plt.xlabel(\"z\")\n",
    "                    plt.ylabel(\"y\")\n",
    "                    plt.show()\n",
    "                    \"\"\"\n",
    "                    pass\n",
    "                else:\n",
    "                    continue \n",
    "            except : \n",
    "                print(\"the new window has a syntax error\")\n",
    "                return\n",
    "            \n",
    "            hit_id =  row['hit_id']    \n",
    "            ext_func_value = ext_func(r0, R, r)\n",
    "            tmp_candidates.append( [hit_id, ext_func_value] ) \n",
    "        #\"************************************************************************************************************\"\n",
    "        #\"***************************In case of not find CANDIDATES on the working module*****************************\"\n",
    "        #\"************************************************************************************************************\n",
    "        if tmp_candidates == [] :                                            \n",
    "            hit_id_left, hit_id_center, hit_id_right = track[0:3]   \n",
    "            # the track has its first forwarding \n",
    "            if   ( (hit_id_left in left_mod['hit_id'].values ) ): # and  (hit_id_center in mod['hit_id'].values) and (hit_id_right in right_mod['hit_id'].values ) ) : \n",
    "                same_track      = track  \n",
    "                new_tracks.append(same_track)\n",
    "                continue\n",
    "            # the track has its second worwarding     \n",
    "            elif ( (hit_id_left in mod['hit_id'].values )  ):   #and  (hit_center in right_mod['hit_id'].values) ):\n",
    "                # Add to weak_tracks    \n",
    "                if(   len(track) == 3 ) :\n",
    "                    weak_tracks.append(track)\n",
    "                    continue \n",
    "                elif( len(track) >  3 ):\n",
    "                    same_track   = track  \n",
    "                    frozen_tracks.append(same_track)\n",
    "                    continue\n",
    "        # \"************************************************************************************************************\" \n",
    "        # \"************   Choosing new hit_id to complete the track.  *************************************************\" \n",
    "        # \"************************************************************************************************************\"     \n",
    "        df_candidates = pd.DataFrame(tmp_candidates, columns=[\"hit_id\", \"ext_fun\"])\n",
    "        if len(tmp_candidates) == 0 : \n",
    "            print(\"an error ocurred with df_candidates\")\n",
    "            return \"error\"\n",
    "        new_hit_id    = df_candidates.loc[df_candidates['ext_fun'].idxmin()]['hit_id']\n",
    "        new_hit_id    = int(new_hit_id)\n",
    "        # \"************************************************************************************************************\" \n",
    "        # \"************   MARKING EACH HIT like \"USED\" ON THE WORKING MODULE  *****************************************\" \n",
    "        # \"************************************************************************************************************\"     \n",
    "        # work_module.loc[ work_module.hit_id == new_hit_id, \"used\" ]  = True \n",
    "        work_module.loc[ work_module.hit_id == new_hit_id, \"used\" ]  += 1 \n",
    "        new_track     =  [new_hit_id] + track  \n",
    "        new_tracks.append(new_track)\n",
    "    return new_tracks  # this value will be replaced by tracks on the main algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doing_plots(df, tracks, name):    \n",
    "    matplotlib.rc('text', usetex=True)\n",
    "    matplotlib.rcParams['text.latex.preamble'] = [r'\\boldmath']\n",
    "\n",
    "    # List will be used to create a text file \n",
    "    # Create plots to show the reconstructed tracks\n",
    "\n",
    "    #df_real_tracks = df.groupby(['particle_id'])['hit_id'].unique() \n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    #tracks = tracks.to_list() + weak_tracks \n",
    "\n",
    "    for track in tracks:\n",
    "        # Here I can get the values of the orignal dataframe.\n",
    "        #data = []\n",
    "        #for hit in track : # \n",
    "        #    data.append(list(df.query(f\"hit_id == {hit}\").values[0])) # what kind of data we want.\n",
    "        #data = pd.DataFrame(data, columns=list(df.columns.values) )\n",
    "        #print(\"dataframe: \", data[['z', 'y']])\n",
    "        \n",
    "        z = df.query(f\"hit_id == {track}\")['z'].tolist()\n",
    "        y = df.query(f\"hit_id == {track}\")['y'].tolist()\n",
    "        \n",
    "        \n",
    "        plt.plot(z, y, '-', alpha=0.8, lw=2)\n",
    "        plt.scatter(z, y, marker='+' )\n",
    "        #print(data['hit_id'])\n",
    "        #plt.plot(data['z'], data['y'], '-', alpha=0.8, lw=2)\n",
    "        #plt.scatter(data['z'], data['y'], marker='+' )\n",
    "\n",
    "        #plt.plot(df['z'], df['y'], '-', alpha=0.8, lw=2, color='C0')\n",
    "        plt.xlabel(r\"\\textbf{Z} [mm]\")\n",
    "        plt.ylabel(r'\\textbf{Y} [mm]')\n",
    "        plt.grid(True)\n",
    "        # tracks.append(data['hit_id'])\n",
    "    plt.scatter(df['z'], df['y'], marker='+', color='b')\n",
    "    for particle_id in df.particle_id.unique() : \n",
    "        plt.plot(   df.query(f\"particle_id =={particle_id}\")['z'], df.query(f\"particle_id =={particle_id}\")['y'], '-', alpha=0.1, lw=1, color='k')\n",
    "    \n",
    "    plt.savefig(f\"{name}_ZY.png\")\n",
    "    plt.show() \n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    for track in tracks:\n",
    "        # Here I can get the values of the orignal dataframe.\n",
    "        #data = []\n",
    "        #for hit in track : # \n",
    "        #     data.append(list(df.query(f\"hit_id == {hit}\").values[0])) # what kind of data we want.\n",
    "        #data = pd.DataFrame(data, columns=list(df.columns.values) )\n",
    "        #print(\"dataframe: \", data[['z', 'y']])\n",
    "        \n",
    "        z = df.query(f\"hit_id == {track}\")['z'].tolist()\n",
    "        x = df.query(f\"hit_id == {track}\")['x'].tolist()\n",
    "        \n",
    "        plt.plot(z, x, '-', alpha=0.8, lw=2)\n",
    "        plt.scatter(z, x, marker='+' )\n",
    "        #print(data['hit_id'])\n",
    "        #plt.plot(data['z'], data['y'], '-', alpha=0.8, lw=2)\n",
    "        #plt.scatter(data['z'], data['y'], marker='+' )\n",
    "        \n",
    "        #plt.plot(df['z'], df['x'], '-', alpha=0.8, lw=2, color='C0')\n",
    "        plt.xlabel(r\"\\textbf{Z} [mm]\")\n",
    "        plt.ylabel(r'\\textbf{X} [mm]')\n",
    "        plt.grid(True)\n",
    "    plt.scatter(df['z'], df['x'], marker='+', color='b' )\n",
    "    for particle_id in df.particle_id.unique() : \n",
    "        plt.plot(   df.query(f\"particle_id =={particle_id}\")['z'], df.query(f\"particle_id =={particle_id}\")['x'], '-', alpha=0.2, lw=1, color='k')\n",
    "    plt.savefig(f\"{name}_ZX.png\")\n",
    "    plt.show() \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    for track in tracks:\n",
    "        # Here I can get the values of the orignal dataframe.\n",
    "        #data = []\n",
    "        #for hit in track : # \n",
    "        #     data.append(list(df.query(f\"hit_id == {hit}\").values[0])) # what kind of data we want.\n",
    "        #data = pd.DataFrame(data, columns=list(df.columns.values) )\n",
    "        #print(\"dataframe: \", data[['z', 'y']])\n",
    "        \n",
    "        y = df.query(f\"hit_id == {track}\")['y'].tolist()\n",
    "        x = df.query(f\"hit_id == {track}\")['x'].tolist()\n",
    "        \n",
    "        plt.plot(x, y, '-', alpha=0.8, lw=2)\n",
    "        plt.scatter(x, y, marker='+' )\n",
    "        #print(data['hit_id'])\n",
    "        #plt.plot(data['z'], data['y'], '-', alpha=0.8, lw=2)\n",
    "        #plt.scatter(data['z'], data['y'], marker='+' )\n",
    "        plt.scatter(df['x'], df['y'], marker='+' )\n",
    "        #plt.plot(   df['x'], df['y'], '-', alpha=0.8, lw=2, color='C0')\n",
    "        plt.xlabel(r\"\\textbf{Y} [mm]\")\n",
    "        plt.ylabel(r'\\textbf{X} [mm]')\n",
    "        plt.grid(True)\n",
    "        # tracks.append(data['hit_id'])\n",
    "    \n",
    "    plt.scatter(df['x'], df['y'], marker='+', color='b')        \n",
    "    for particle_id in df.particle_id.unique() : \n",
    "        plt.plot(   df.query(f\"particle_id =={particle_id}\")['x'], df.query(f\"particle_id =={particle_id}\")['y'], '-', alpha=0.2, lw=1, color='k')\n",
    "    plt.savefig(f\"{name}_XY.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_histogram(tracks):\n",
    "    global df\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    time_difference = []\n",
    "    for track in tracks : \n",
    "        for i_hit in range(1, len(track), 1):\n",
    "            hit1 = track[i_hit-1]\n",
    "            hit2 = track[i_hit]\n",
    "            t1 = df.query(f\"hit_id == {hit1}\")['t_c'].values[0]\n",
    "            t2 = df.query(f\"hit_id == {hit2}\")['t_c'].values[0]\n",
    "            time_difference.append(t2 - t1)  \n",
    "    plt.hist(time_difference)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### MAIN ###############################################\n",
    "########################################################################################\n",
    "############################ GENERAL ALGORITHM #########################################\n",
    "########################################################################################\n",
    "########################################################################################\n",
    "\n",
    "# Probably I can put on this \n",
    "def search_by_triplet( TIME_RESOLUTION = True):\n",
    "    global flagged\n",
    "    global sigma_z_origin\n",
    "    global dx, dy\n",
    "    global frozen_tracks\n",
    "    global M_i\n",
    "    global event, df, time_resolution    \n",
    "    global fraction, df\n",
    "    global modules, dphi, mod, right_mod, left_mod, sigma_t, work_module, sigma_z, tracks, weak_tracks\n",
    "    time_resolution = TIME_RESOLUTION \n",
    "    \n",
    "    ### switch time ###...\n",
    "    if   time_resolution == True:                                             # on all cases where be necessary\n",
    "        print(\"the TIME_RESOLUTION is activated ... \")                        # implement timing information here \n",
    "    ### switch time ###...\n",
    "    elif time_resolution == False:                                            # on all cases where be necessary\n",
    "        print(\"the TIME_RESOLUTION is de-activated ... \")                     # on all cases where be necessary\n",
    "    T1 = time.time()  # Timing The Run-Time\n",
    "    ########################################################################################\n",
    "    ###############################   PARAMETERS   #########################################\n",
    "    ########################################################################################\n",
    "    flagged  = 2\n",
    "    dx       = 0.15          # General Parameters [mm]                                                      \n",
    "    dy       = 0.15          # General Parameters [mm]                                                     \n",
    "    event    = 3            # General Parameters \n",
    "    sigma_t  = 500           # General Parameters [ps] \n",
    "    sigma_z  = 0.5          # General Parameters [mm] \n",
    "    sigma_z_origin = 3*50   # 50mm               [mm] \n",
    "    fraction = 1            # General Parameters \n",
    "    dphi     = 0.01         # The windows is a variable quantity that depend on phi_ext_base \n",
    "    #phi_window =           # phi_extrapolation_base + np.abs( hit_Zs[h_center]) * phi_extrapolation_coef\n",
    "    #phi_extrapolation_coef = 0.02 \n",
    "    #phi_extrapolation_base = 0.03 \n",
    "    m = 24                  # number of modules counted from the left. from 1 to 24. No more. \n",
    "    ########################################################################################\n",
    "    ########################################################################################\n",
    "    ######################################################################################## \n",
    "    \n",
    "    new_tracks    = []                   # where data is unmodified.   \n",
    "    frozen_tracks = []                   # these tracks are formed by more than 4 hits, it is important that, it will be joined with the frozen_tracks \n",
    "    tracks        = []                   # \n",
    "    weak_tracks   = []                   # \n",
    "    df = reading_data(fraction, event)   # where data is unmodified.\n",
    "    \n",
    "    \n",
    "    \n",
    "    # *********************IMPORTANT********************************************************\n",
    "    # The information of tracks is ordered. \n",
    "    # Because, each of its elements are an ordered list according to module layers.\n",
    "    # However, the information of hits are unique and not matter if they are a ordered set. \n",
    "    # But it was filled out in order\n",
    "\n",
    "    # SEPARATION BY MODULE  \n",
    "    modules = sortbyphi()                    # this line modify df adding the z_correct\n",
    "    # print(\"second_error\", len(modules[0]))   \n",
    "    #for i in range(len(modules)):             \n",
    "    #    print(modules[i]['t_c'])            # \n",
    "    # FIND CANDIDATE WINDOWS. In order to minimize the amount of candidates considered in subqsequent steps.\n",
    "    ################################################    \n",
    "    ###### Ordering Modules Accordig to Phi: #######\n",
    "    ################################################\n",
    "    print(\"ordering modules accordig to phi: \")\n",
    "    for M_i in range(len(modules)-1-1, len(modules)-m-2, -1): \n",
    "        #M_i = M_i - 1\n",
    "        left_mod     =  modules[M_i - 1] #.copy(deep=True)      \n",
    "        mod          =  modules[M_i    ] #.copy(deep=True)   \n",
    "        right_mod    =  modules[M_i + 1] #.copy(deep=True)  \n",
    "        modules[M_i] =  findcandidatewindows(left_mod, mod, right_mod).copy(deep=True)\n",
    "\n",
    "    ######PRINCIPAL LOOP OVER MODULES########\n",
    "    #########################################   \n",
    "    #########################################    \n",
    "    # ITERATION OVER MODULES ( ):\n",
    "\n",
    "    for M_i in range(len(modules)-1-1, len(modules)-m-2, -1) :  # the number two is due to 1. index postion default. 2. \n",
    "        \n",
    "        t1 = time.time()    # TIMING THE RUNNING OVER A MODULE             \n",
    "        print(f\"module number {M_i}\")\n",
    "        #M_i = M_i - 1\n",
    "        #1th STEP:  ASIGNING NOTATION\n",
    "        left_mod  =  modules[M_i - 1]#.copy(deep=True)   \n",
    "        mod       =  modules[M_i    ]#.copy(deep=True)   \n",
    "        right_mod =  modules[M_i + 1]#.#copy(deep=True)\n",
    "\n",
    "        new_seeds = trackseeding() \n",
    "        \n",
    "        name = f\"center_module_{M_i}\"\n",
    "        #doing_plots(df, new_seeds,name)\n",
    "        #\"\"\"\n",
    "        #Adding new seeds to tracks \n",
    "        tracks    = tracks + new_seeds \n",
    "        # REASIGNING VALUES    \n",
    "        modules[M_i - 1] = left_mod.copy( deep=True)           \n",
    "        modules[M_i    ] = mod.copy(      deep=True)              \n",
    "        modules[M_i + 1] = right_mod.copy(deep=True)        \n",
    "\n",
    "        # Defining a new module.  \n",
    "        work_module      = modules[M_i - 2].copy(deep=True) \n",
    "        \n",
    "        new_tracks       = track_forwarding()         \n",
    "        tracks           = new_tracks\n",
    "        name = f\"tracks_at_step_{M_i}\"\n",
    "        #doing_plots(df, tracks,name)\n",
    "        \n",
    "        modules[M_i - 2] = work_module.copy(deep=True)\n",
    "        \n",
    "        t2 = time.time()\n",
    "        print(\"time per module\", t2-t1)  \n",
    "        \n",
    "    #tracks = tracks + frozen_tracks    \n",
    "    print(\"FINDING TRACKS FINISHED\") \n",
    "    T2 = time.time()# Timing The Run-Time\n",
    "    print(\"RUN TOTAL TIME PER EVENT IS : \", T2-T1) \n",
    "        \n",
    "    df_real_tracks = df.groupby(['particle_id'])['hit_id'].unique()  \n",
    "    #df_real_tracks = df_real_tracks[df_real_tracks.apply(len) > 2]\n",
    "    if len(tracks) > 0 :\n",
    "        print(\"********************************************************\")\n",
    "        print(\"SCORING using tracks\")              \n",
    "        print(Scoring(df_real_tracks, tracks))\n",
    "        time_histogram(tracks)\n",
    "    if len(weak_tracks) > 0 :  \n",
    "        print(\"********************************************************\")\n",
    "        print(\"SCORING using weak_tracks\")\n",
    "        print(Scoring(df_real_tracks, weak_tracks))\n",
    "        time_histogram(weak_tracks)\n",
    "    if len(frozen_tracks) > 0 : \n",
    "        print(\"********************************************************\")\n",
    "        print(\"SCORING using frozen_tracks\")  \n",
    "        print(Scoring(df_real_tracks, frozen_tracks))\n",
    "        time_histogram(frozen_tracks)\n",
    "    if len( tracks + frozen_tracks + weak_tracks ) > 0 : \n",
    "        print(\"********************************************************\")\n",
    "        print(\"SCORING using all tracks\")  \n",
    "        print(Scoring(df_real_tracks, tracks + frozen_tracks + weak_tracks))\n",
    "        time_histogram(tracks + frozen_tracks + weak_tracks)\n",
    "    else :\n",
    "        print(\"********************************************************\")\n",
    "        print(\"Absolutely no track is founded: \")\n",
    "    #\"\"\"\n",
    "    doing_plots(df, tracks+frozen_tracks+weak_tracks, name=\"proof\")\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the TIME_RESOLUTION is activated ... \n",
      "ordering modules accordig to phi: \n",
      "module number 24\n",
      "time per module 41.37637805938721\n",
      "module number 23\n",
      "time per module 57.89176821708679\n",
      "module number 22\n",
      "time per module 38.0133490562439\n",
      "module number 21\n",
      "time per module 31.933762311935425\n",
      "module number 20\n",
      "time per module 43.356101512908936\n",
      "module number 19\n",
      "time per module 50.608591079711914\n",
      "module number 18\n",
      "time per module 49.340303897857666\n",
      "module number 17\n",
      "time per module 55.252771615982056\n",
      "module number 16\n",
      "time per module 60.157097816467285\n",
      "module number 15\n",
      "time per module 56.22938323020935\n",
      "module number 14\n",
      "time per module 52.78634285926819\n",
      "module number 13\n",
      "time per module 50.01727485656738\n",
      "module number 12\n",
      "time per module 46.794825315475464\n",
      "module number 11\n",
      "time per module 41.95768904685974\n",
      "module number 10\n",
      "time per module 31.322285890579224\n",
      "module number 9\n",
      "time per module 24.03209924697876\n",
      "module number 8\n",
      "time per module 15.99175214767456\n",
      "module number 7\n",
      "time per module 20.078044414520264\n",
      "module number 6\n",
      "time per module 31.05204749107361\n",
      "module number 5\n",
      "time per module 36.81598949432373\n",
      "module number 4\n",
      "time per module 35.97734332084656\n",
      "module number 3\n",
      "time per module 51.09443402290344\n",
      "module number 2\n",
      "time per module 61.39523124694824\n",
      "module number 1\n",
      "time per module 45.11380219459534\n",
      "FINDING TRACKS FINISHED\n",
      "RUN TOTAL TIME PER EVENT IS :  1086.4661538600922\n",
      "********************************************************\n",
      "SCORING using tracks\n",
      "{'efficiency': 0.25038520801232667, 'fake_rate': 0.48738170347003157, 'clone_rate': 0.45110410094637227}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************\n",
      "SCORING using weak_tracks\n",
      "{'efficiency': 0.21956856702619415, 'fake_rate': 0.2803030303030303, 'clone_rate': 0.005050505050505051}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************\n",
      "SCORING using frozen_tracks\n",
      "{'efficiency': 0.5839753466872111, 'fake_rate': 0.47324530924252955, 'clone_rate': 0.4100069492703266}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************\n",
      "SCORING using all tracks\n"
     ]
    }
   ],
   "source": [
    "search_by_triplet(TIME_RESOLUTION = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
