{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from split import *\n",
    "from score import *\n",
    "#from scipy.stats import chi2\n",
    "from scipy import interpolate\n",
    "import time \n",
    "%matplotlib inline \n",
    "# When I was implementing the algorithm Search_by_Triplet I see that PANDAS can do data selections\n",
    "# more easily. The  query method gives us this possibility. \n",
    "# Not have sense to implement the orderring of data and similar things. \n",
    "# This line of code is to delete warnings. Specifically to rtankwarning of polyfit \n",
    "import warnings\n",
    "warnings.simplefilter('ignore', np.RankWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho(x,y):\n",
    "    return np.sqrt(x*x + y*y)\n",
    "def r(x,y,z):\n",
    "    return np.sqrt(x*x + y*y + z*z)\n",
    "def theta(x,y,z):\n",
    "    return np.arccos(z/r(x,y,z))\n",
    "def phi(x,y):\n",
    "    return np.arctan(y/x)\n",
    "def module(r):\n",
    "    return np.sqrt(np.sum(r*r))\n",
    "def r_e(z, r_l, r_c):\n",
    "    #z   is a scalar. It is the position where we want to extrapolate. \n",
    "    #r_l is an array\n",
    "    #r_c is an another array \n",
    "    z_c = r_c[2] \n",
    "    r_versor = (r_l - r_c)/module(r_l - r_c)               # computing r_versor\n",
    "    r_versor_dot_z_versor = r_versor[2]  \n",
    "    return r_c - r_versor/r_versor_dot_z_versor*(z_c - z)  # IMPORTANT WITH THE MINUS SIGN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['theta'] = df.apply(lambda row: theta(row['x'], row['y'], row['z'] ), axis=1)\n",
    "#df['phi']   = df.apply(lambda row: phi  (row['x'], row['y']),   axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_data(fraction):\n",
    "    name = 'data/RAMPData55microns50psInner200microns50psOuter_train.txt' # To be modified for others. \n",
    "    data_fraction = fraction\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.read_csv(name, sep=' ') # All data.\n",
    "    df,_ = Split_frac(df, data_fraction)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATAFRAME will be a global data. \n",
    "fraction = 0.004 \n",
    "dphi     = 0.01         #this information is a parameter that have to be evaluated as a function of time. \n",
    "\n",
    "df_original = reading_data(fraction)  # where data is unmodified.\n",
    "df          = df_original \n",
    "df_search   = df_original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortbyphi(df):\n",
    "    '''Description:\n",
    "    Sort each D_i increasingly accourding to phi\n",
    "    '''\n",
    "    z = np.sort(df['z'].unique())\n",
    "    df['phi'] = np.arctan(df['x']/df['y']) \n",
    "    modules = [] \n",
    "    for layer_i in z[::-1] :\n",
    "        tmp = df.query(f'z=={layer_i}')\n",
    "        #tmp['phi'] = tmp.apply(lambda row: phi(row['x'], row['y']), axis=1)\n",
    "        \n",
    "        tmp = tmp.sort_values('phi', ascending=True)\n",
    "        modules.append(tmp)\n",
    "    return modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findcandidatewindows(left_mod, mod, right_mod, dphi):\n",
    "    '''Description: \n",
    "        Compute the first and last candidates(the window) according to acceptance range(dphi) for each hit.\n",
    "        SUPPOSSING THAT ALL DATA ARE ORDERED ACCOURDING TO PHI. THIS PROCCESS WAS DONE Previously\n",
    "        In case of add more information to the modules, one easily can add throught the iteration \n",
    "    '''\n",
    "    # CONVETION:     \n",
    "    # l_m m  r_m         \n",
    "    # |   |   |             \n",
    "    # |   |   |    phi max  \n",
    "    # |   |   |    phi      \n",
    "    # |   |   |    phi min \n",
    "    # |   |   |             \n",
    "    # The module in question is the one in the center\n",
    "    #left_mod, mod, right_mod = modules \n",
    "    #dphi = acceptance_range  \n",
    "    \n",
    "    # This algorithm no develop a binary search. After, an intersting enhacement woudl be develop a function\n",
    "    # in shuch a way that return the values of the condition\n",
    "    \n",
    "    #tmp = [] # Here I put the hit values related to right_hit_max, right_hit_min, or left_hit_max, left_hit_min\n",
    "    \n",
    "    #condition = f' {phi} - {dphi} < phi < {phi} - {dphi}' # condition\n",
    "    #tmp = mod.query(condition)                            # defining the possibles hits\n",
    "    #tmp['hit_id'][tmp.index[0]]       # the first hit   \n",
    "    #tmp['hit_id'][tmp.index[-1]]      # the last  hit                                                    \n",
    "\n",
    "    \n",
    "    right_hit_max = [] \n",
    "    right_hit_min = [] \n",
    "    # ITERATION OVER PHI for RIGHT                     # ???????????????????? Here there are problems if not found values.\n",
    "    for phi_i in mod['phi']:  \n",
    "        # GET HIT \n",
    "        left      = phi_i - dphi\n",
    "        right     = phi_i + dphi\n",
    "        condition = f'{left} <= phi <= {right}'\n",
    "        tmp_df    = right_mod.query(condition)\n",
    "        #Getting the minimum and maximum\n",
    "\n",
    "        m = 1 #tmp_df['hit_id'][tmp_df.index[0]]    # minumum hit\n",
    "        M = 1000 #tmp_df['hit_id'][tmp_df.index[-1]]   # maximum hit\n",
    "        right_hit_min.append(m)\n",
    "        right_hit_max.append(M)\n",
    "\n",
    "    left_hit_max = [] \n",
    "    left_hit_min = [] \n",
    "    # ITERATION OVER PHI FOR LEFT\n",
    "    for phi_i in mod['phi']:  \n",
    "        # GET HIT \n",
    "        left      = phi_i - dphi\n",
    "        right     = phi_i + dphi                                                                                                             \n",
    "        condition = f'{left} <= phi <= {right}'\n",
    "        tmp_df = right_mod.query(condition)\n",
    "        #Getting the minimum and maximum\n",
    "        m = 1 #tmp_df['hit_id'][tmp_df.index[0]]    # minumum hit\n",
    "        M = 1000 \n",
    "        #m = tmp_df['hit_id'][tmp_df.index[0]]    # minumum hit\n",
    "        #M = tmp_df['hit_id'][tmp_df.index[-1]]   # maximum hit\n",
    "        left_hit_min.append(m)\n",
    "        left_hit_max.append(M)\n",
    "    \n",
    "    # At the end of the algorithm we add the values of the left and right modules\n",
    "\n",
    "    mod[\"right_hit_max\"] = right_hit_max\n",
    "    mod[\"right_hit_min\"] = right_hit_min\n",
    "    \n",
    "    mod[\"left_hit_max\"]  = left_hit_max\n",
    "    mod[\"left_hit_min\"]  = left_hit_min\n",
    "    \n",
    "    # With the help of two modules(left and riht)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trackseeding(mod, left_mod, right_mod):\n",
    "    \n",
    "    # mod_i are dataframes.\n",
    "    # mod have the number of hits of max and min phi values. \n",
    "    # mod[] mod[]\n",
    "    \n",
    "    ''' \n",
    "    mod[\"right_hit_max\"] = right_hit_max\n",
    "    mod[\"right_hit_min\"] = right_hit_min\n",
    "    \n",
    "    mod[\"left_hit_max\"]  = left_hit_max\n",
    "    mod[\"left_hit_min\"]  = left_hit_min\n",
    "    ''' \n",
    "    \n",
    "    '''Description: \n",
    "        Checks the preceding and following modules for compatible hits using the above results.\n",
    "        \n",
    "        All triplets in the search window are fitted and compared.\n",
    "        \n",
    "        and the best one is kept as a track seed.\n",
    "        \n",
    "        stores its best found triplet\n",
    "        Finding triplets is ap- plied in first instance to the modules\n",
    "        that are further apart from the collision point\n",
    "        Each triplet is the seed of a forming track\n",
    "    '''\n",
    "    #Necessary functions.\n",
    "    def fit(triplet):\n",
    "        phi_data = [ df.query(f'hit_id == {hit}')['phi'] for hit in triplet ]\n",
    "        z_data   = [ df.query(f'hit_id == {hit}')['z'] for hit in triplet ]\n",
    "        phi_data = [ hit.values[0] for hit in phi_data ]\n",
    "        z_data   = [ hit.values[0] for hit in z_data ]\n",
    "\n",
    "\n",
    "        #print(phi_data)\n",
    "        #print(z_data)\n",
    "\n",
    "        #plt.plot(phi_data, z_data)\n",
    "\n",
    "        # Kind of fit: Linear\n",
    "        fitting = np.polyfit(phi_data, z_data, 1)\n",
    "\n",
    "        chiSquared = np.sum((np.polyval(fitting, z_data) - phi_data)**2) \n",
    "        return chiSquared \n",
    "    \n",
    "       \n",
    "    df_triplets = []\n",
    "    for part in mod.iterrows():\n",
    "        part = (part[1])  # IMPORTANT\n",
    "        \n",
    "        # hit_id\n",
    "        # This process is neccessary \n",
    "        r_hit_max, r_hit_min = part[\"right_hit_max\"], part[\"right_hit_min\"]  \n",
    "        l_hit_max, l_hit_min = part[\"left_hit_max\"],  part[\"left_hit_min\" ]  \n",
    "        \n",
    "        r_phi_max = right_mod.query(f\"hit_id == {r_hit_max}\")\n",
    "        r_phi_min = right_mod.query(f\"hit_id == {r_hit_min}\")\n",
    "        \n",
    "        l_phi_max = left_mod.query(f\"hit_id == {l_hit_max}\")  \n",
    "        l_phi_min = left_mod.query(f\"hit_id == {l_hit_min}\")  \n",
    "        \n",
    "        #Forming all Triplets. \n",
    "\n",
    "        tmp_left = df.query(f\" {l_hit_min} <= phi <= {l_hit_max}\")\n",
    "               \n",
    "        for L in tmp_left['phi'].values: \n",
    "            tmp_right = df.query(f\" {r_hit_min} <= phi <= {r_hit_max}\")\n",
    "            for R in tmp_right['phi'].values:\n",
    "                \n",
    "        \n",
    "                # All information it is found on the hit values.\n",
    "                hit_center = int(part[\"hit_id\"])             \n",
    "                hit_left   = int(tmp_left.query(f\" phi == {L}\")['hit_id'].values)       \n",
    "                hit_right  = int(tmp_right.query(f\" phi == {R}\")['hit_id'].values)                          \n",
    "                \n",
    "                # With this data we have built the triplets. \n",
    "                triplets = [hit_left, hit_center, hit_right]\n",
    "                # This a lost of memory. I mean that call by hits and not by values is a lost \n",
    "                # of memory.\n",
    "                chi2 = fit(triplets)\n",
    "                # Finally we append the values of the data to a df_triplets\n",
    "                \n",
    "                #print(\"####?###\")\n",
    "                #print(triplets)\n",
    "                #print(chi2)\n",
    "                #print(\"#######\")\n",
    "                df_triplets.append(list(triplets)+[chi2])\n",
    "    df_triplets = pd.DataFrame(df_triplets, columns = ['lef_hit', 'hit', 'right_hit', 'chi2']) \n",
    "    #        print(\"=========\")\n",
    "    #        print(df_triplets)\n",
    "    #        print(\"=========\")    \n",
    "    # Up to this point it is necessary to have the values of df_triplets complete\n",
    "    # Then the algorithm should continue to get the best choices according to the values\n",
    "    # of chi2.  \n",
    "              \n",
    "    def best_choice(df_triplets):\n",
    "        tracks = []\n",
    "        for hit_c in df_triplets['hit'].values :\n",
    "            #print(hit_c)\n",
    "            tmp = df_triplets.query(f'hit == {hit_c}')\n",
    "            #print(tmp)\n",
    "            m = (tmp['chi2']).idxmin()\n",
    "            #i = chi2values.idxmin() # Here we choice the values.\n",
    "            #tracks.append((tmp.loc[i]).values) \n",
    "            t = (tmp.loc[m]).values\n",
    "            #print(t)\n",
    "            #print(t[:3])\n",
    "\n",
    "            tracks.insert(0, list(t[:3]))\n",
    "        return tracks\n",
    "    \n",
    "    tracks = best_choice(df_triplets)\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_forwarding(tracks, work_module, dphi):\n",
    "    new_tracks = [] \n",
    "    \n",
    "    #Notation:\n",
    "    # x0, y0, z0 is the EXTRAPOLATED track.               \n",
    "    # X,  Y,  Z  is the last track on previous module.   \n",
    "    # x,  y,  z  is the tracks on a window.                                                                 \n",
    "    #Searching tracks on phi_e - dphi < phi < d that minimize the extrapolated function.\n",
    "    #r0 = np.array([x0, y0, z0] )\n",
    "    #r  = np.array([x, y, 1] )\n",
    "    #R  = np.array([X,  Y,  Z ] )\n",
    "    def mod(r):\n",
    "        return np.sqrt(np.sum(r*r))\n",
    "    def ext_func(r0, r1, r):\n",
    "        # r0, r1, r are arrays\n",
    "        dx2_plus_dy2 = mod(r0-r)  # distance between hits on the working module.\n",
    "        dz2          = mod(r1-r0) # distance between the last two modules.                              \n",
    "        return dx2_plus_dy2/dz2   \n",
    "    \n",
    "    \n",
    "    z_e = float(work_module['z'].unique()) #z_position of work_module\n",
    "    #phi_e\n",
    "    #x_e\n",
    "    #y_e\n",
    "    #z_e\n",
    "    \n",
    "    # here the track is exactly the seed. Only for the 1th iteration\n",
    "    \n",
    "    for track in tracks: \n",
    "        data = []    \n",
    "        vector_data = []\n",
    "        for hit in track[0:2] : # Iteration over the 2 last modules to a module extrapolation.    \n",
    "                                # IMPORTANT. I AM SUPPOSING THAT THE HITS ARE in separate modules.\n",
    "            data.append(tuple((df.query(f'hit_id == {hit}')[['phi', 'z']]).values[0]))     \n",
    "            vector_data.append(tuple((df.query(f'hit_id == {hit}')[['x', 'y', 'z']]).values[0]))  \n",
    "        \n",
    "        phi_data, z_data = zip(*data)\n",
    "        #print(vector_data)\n",
    "        #EXTRAPOLATED SEGMENT FUNCTION  \n",
    "        ext_seg = interpolate.interp1d(z_data, phi_data, fill_value = \"extrapolate\" )\n",
    "        phi_e = ext_seg(z_e)\n",
    "        \n",
    "        r_l, r_c = vector_data \n",
    "        r_l, r_c = np.array(r_l), np.array(r_c)\n",
    "        \n",
    "        x_e, y_e, z_e = r_e(z_e, r_l, r_c) # COMPUTING THE VALUES ON THE WORKING MODULE. It is good.\n",
    "        \n",
    "        #PROOF, HERE THE VALUE OF Z_E SHOULD BE THE SAME ON BOTH ********** IMPORTANT \n",
    "        \n",
    "        #depend on z_e\n",
    "        #y_e = #depend on z_e      \n",
    "        \n",
    "        #Open a Window centered on phi_e: \n",
    "        \n",
    "        phi_a = phi_e - dphi\n",
    "        phi_b = phi_e + dphi \n",
    "        \n",
    "        df_work_module_window = work_module.query(f\" {phi_a} <= phi <= {phi_b} \" ) # I do not know how much time this line take \n",
    "        \n",
    "        #This definition will be done after the loop.\n",
    "        #df_candidates = pd.DataFrame(columns=[\"hit_id\", \"ext_fun\"]) # This dataframe have to be reviwed\n",
    "        \n",
    "        \n",
    "        hit_left = track[0]   \n",
    "        R  = df.query(f'hit_id == {hit_left}')[['x','y','z']].values[0] # this value would have to change on each track\n",
    "        r0 = np.array([x_e, y_e ,z_e ])\n",
    "        \n",
    "        \n",
    "        print(R, \"this is R\")\n",
    "        print(r0, \"this is r0\")\n",
    "        tmp_candidates = []\n",
    "        for index, row in df.iterrows(): # here the index is not important\n",
    "            # Here I only need to have the information of position.\n",
    "            r      =  row[['x', 'y', 'z']].values # this value is variable on each row.\n",
    "            hit_id =  row['hit_id']    \n",
    "            \n",
    "            print(\"PROOF\")\n",
    "            print(r, hit_id)\n",
    "            #Then I compute the value \n",
    "            ext_func_value = ext_func(r0, R, r)\n",
    "            tmp_candidates.append( [hit_id, ext_func_value] )\n",
    "            print(tmp_candidates)\n",
    "        \n",
    "        if tmp_candidates == []:                                            \n",
    "            print(\"an error ocurred: with tmp_candidates is empty \")                                          \n",
    "            break                                                                                              \n",
    "        \n",
    "        print(\"=====\")\n",
    "        print(tmp_candidates)\n",
    "        print(\"=====\")\n",
    "        \n",
    "        df_candidates = pd.DataFrame(tmp_candidates, columns=[\"hit_id\", \"ext_fun\"])\n",
    "        #if \n",
    "        \n",
    "        # Finally \n",
    "        \n",
    "        # I will find the minimum value of the extrapolation function \n",
    "        print(\"df_candidadtes \")\n",
    "        print(df_candidates['ext_fun'])\n",
    "        print(\"df_candidadtes\")    \n",
    "        index      = df_candidates['ext_fun'].idxmin()   \n",
    "        new_hit_id = df_candidates['hit_id'][index]    \n",
    "        new_track  = [new_hit_id] + track                            \n",
    "        new_tracks.append(new_track)        \n",
    "        # \n",
    "    return new_tracks # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GENERAL_ALGORITHM():\n",
    "    global tracks      \n",
    "    fraction = 0.004    \n",
    "    dphi     = 0.01       \n",
    "    \n",
    "    df_original = reading_data(fraction)  # where data is unmodified.\n",
    "    df_search   = df_original             # where I am searching \n",
    "    tracks = []                           # [[1,24, 5], [7,6,4] ,[346,7,32,], ... ]\n",
    "    \n",
    "    #SEPARATION BY MODULE\n",
    "    modules = sortbyphi(df_original) \n",
    "    df = df_original                      # df is global variable \n",
    "\n",
    "    m = len(modules)                         # number of modules\n",
    "    n = len(df_original['hit_id'].unique())  # number of hits                                             \n",
    "       \n",
    "    #ITERATION OVER MODULES ( ):\n",
    "    for M_i in range(len(modules)-1, 2, -1):\n",
    "        t1 = time.time()\n",
    "        print(f\"module number {M_i}\")\n",
    "        M_i = M_i - 1\n",
    "        #1th STEP: module #m-1 = M_i\n",
    "        left_mod  =  modules[M_i - 1]\n",
    "        mod       =  modules[M_i    ]\n",
    "        right_mod =  modules[M_i + 1]                                                                       \n",
    "        \n",
    "        print(\" DOING  ... findcandidatewindows \")\n",
    "        mod       = findcandidatewindows(left_mod, mod, right_mod, dphi)\n",
    "        print(\" ENDING ... findcandidatewindows \")\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(\"################################TRACKS###############################\")\n",
    "        #print(tracks) \n",
    "        #print(\"module #\", M_i)\n",
    "        tracks      = trackseeding(mod, left_mod, right_mod)\n",
    "        work_module = modules[M_i - 2]\n",
    "        tracks      = track_forwarding(tracks, work_module, dphi)  # return new tracks\n",
    "        t2          = time.time()\n",
    "        print(\"time per module\", t2-t1) \n",
    "    return tracks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weaktrackfilter():\n",
    "    '''Description: '''\n",
    "    #               \n",
    "    #                \n",
    "    #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing Proofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-01c4f176e8c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdphi\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreading_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# where data is unmodified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_search\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mdf_original\u001b[0m\u001b[0;31m# where I am searching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mdf_original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-02a9700b2dd4>\u001b[0m in \u001b[0;36mreading_data\u001b[0;34m(fraction)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# All data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSplit_frac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_fraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "fraction    = 0.004  \n",
    "dphi        = 0.001                                                                                           \n",
    "\n",
    "df_original = reading_data(fraction)     # where data is unmodified.\n",
    "df_search   = df_original# where I am searching \n",
    "df          = df_original\n",
    "tracks      =  []                              # [[1,24, 5], [7,6,4] ,[346,7,32,], ... ]\n",
    "\n",
    "#SEPARATION BY MODULE                    # \n",
    "modules     = sortbyphi(df_original)         #                               \n",
    "df          = df_original                         # \n",
    "\n",
    "m = len(modules)                         # number of modules\n",
    "n = len(df_original['hit_id'].unique())  # number of hits    \n",
    "\n",
    "#GENERAL_ALGORITHM()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
